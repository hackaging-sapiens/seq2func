{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0758b1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Longevity Genes Details Fetcher\n",
    "\n",
    "Fetches additional gene details from HGNC, Ensembl, and NCBI APIs to enrich\n",
    "the master_longivity_genes.csv file with additional gene information.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import requests\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Any, Optional, Tuple\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d246b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80432db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters\n",
    "HGNC_API_URL = \"https://rest.genenames.org/fetch/symbol\"\n",
    "ENSEMBL_API_BASE = \"https://rest.ensembl.org\"\n",
    "NCBI_EUTILS_BASE = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/\"\n",
    "GENAGE_BASE_URL = \"https://genomics.senescence.info\"\n",
    "REQUEST_TIMEOUT = 30\n",
    "RATE_LIMIT_DELAY = 0.34  # NCBI requires <= 3 requests per second\n",
    "HUMAN_TAXONOMY_ID = 9606"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd90a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and output file paths\n",
    "INPUT_CSV = \"master_longivity_genes.csv\"\n",
    "OUTPUT_CSV = \"master_longivity_genes_enriched.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbc9a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_references_from_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove reference citations like [2210], [2215], [4358] from text.\n",
    "    Handles various formats including single references [123], comma-separated [123, 456], \n",
    "    and ranges [123-125].\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text that may contain reference citations\n",
    "        \n",
    "    Returns:\n",
    "        str: Cleaned text with reference citations removed\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return text\n",
    "    \n",
    "    # Multiple patterns to match different reference citation formats\n",
    "    reference_patterns = [\n",
    "        r'\\[\\d+\\]',                    # Single reference [123]\n",
    "        r'\\[\\d+\\s*,\\s*\\d+\\]',         # Comma-separated [123, 456]\n",
    "        r'\\[\\d+\\s*-\\s*\\d+\\]',         # Range references [123-125]\n",
    "        r'\\[\\d+(?:\\s*,\\s*\\d+)*\\]',    # Multiple comma-separated [123, 456, 789]\n",
    "    ]\n",
    "    \n",
    "    # Apply each pattern to remove references\n",
    "    cleaned_text = text\n",
    "    for pattern in reference_patterns:\n",
    "        cleaned_text = re.sub(pattern, '', cleaned_text)\n",
    "    \n",
    "    # Remove spaces before punctuation marks (e.g., \" .\" -> \".\")\n",
    "    cleaned_text = re.sub(r'\\s+([.,;:!?)])', r'\\1', cleaned_text)\n",
    "    \n",
    "    # Clean up any extra whitespace that might have been left behind\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)\n",
    "    cleaned_text = cleaned_text.strip()\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a517769f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input_csv() -> pd.DataFrame:\n",
    "    \"\"\"Read the master longevity genes CSV file.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(INPUT_CSV)\n",
    "        logger.info(f\"Read {len(df)} genes from {INPUT_CSV}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error reading input CSV: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c2940b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_hgnc_data(gene_symbol: str) -> Dict[str, Any]:\n",
    "    \"\"\"Fetch HGNC data for a gene symbol.\"\"\"\n",
    "    try:\n",
    "        headers = {\n",
    "            'Accept': 'application/json',\n",
    "            'User-Agent': 'Longevity-Genes-Fetcher/1.0'\n",
    "        }\n",
    "        \n",
    "        # Use the symbol endpoint to get specific gene data\n",
    "        url = f\"{HGNC_API_URL}/{gene_symbol}\"\n",
    "        \n",
    "        response = requests.get(url, headers=headers, timeout=REQUEST_TIMEOUT)\n",
    "        \n",
    "        if response.status_code == 404:\n",
    "            logger.warning(f\"No HGNC data found for {gene_symbol}\")\n",
    "            return {}\n",
    "        \n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        if 'response' not in data or 'docs' not in data['response']:\n",
    "            logger.warning(f\"Unexpected HGNC response format for {gene_symbol}\")\n",
    "            return {}\n",
    "        \n",
    "        docs = data['response']['docs']\n",
    "        if not docs:\n",
    "            logger.warning(f\"No HGNC docs found for {gene_symbol}\")\n",
    "            return {}\n",
    "        \n",
    "        gene_data = docs[0]  # Take the first (and should be only) result\n",
    "        \n",
    "        # Extract relevant fields\n",
    "        # Handle chromosome extraction from location field (format: \"1p36.33\")\n",
    "        location = gene_data.get('location', '')\n",
    "        chromosome = ''\n",
    "        if location:\n",
    "            # Extract chromosome number from location (e.g., \"1p36.33\" -> \"1\")\n",
    "            parts = location.split()\n",
    "            if parts:\n",
    "                chrom_part = parts[0]\n",
    "                # Extract just the chromosome number/letter\n",
    "                chrom_match = re.match(r'^([1-9][0-9]?|X|Y)', chrom_part)\n",
    "                if chrom_match:\n",
    "                    chromosome = chrom_match.group(1)\n",
    "        \n",
    "        hgnc_data = {\n",
    "            'hgnc_gene_id': gene_data.get('hgnc_id', ''),\n",
    "            'gene_symbol_aliases': ', '.join(gene_data.get('alias_symbol', [])) if gene_data.get('alias_symbol') else '',\n",
    "            'entrez_id': gene_data.get('entrez_id', ''),\n",
    "            'ensembl_gene_id': gene_data.get('ensembl_gene_id', ''),\n",
    "            'chromosome': chromosome,\n",
    "        }\n",
    "        \n",
    "        return hgnc_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Error fetching HGNC data for {gene_symbol}: {e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f6a489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_ensembl_data(gene_symbol: str) -> Dict[str, Any]:\n",
    "    \"\"\"Fetch Ensembl data for a gene symbol including detailed information.\"\"\"\n",
    "    try:\n",
    "        headers = {\n",
    "            'Content-Type': 'application/json',\n",
    "            'Accept': 'application/json',\n",
    "            'User-Agent': 'Longevity-Genes-Fetcher/1.0'\n",
    "        }\n",
    "        \n",
    "        # Search for gene using symbol with expanded data including transcripts\n",
    "        url = f\"{ENSEMBL_API_BASE}/lookup/symbol/homo_sapiens/{gene_symbol}\"\n",
    "        params = {\n",
    "            'expand': 1,  # Include transcripts to get exon count and protein info\n",
    "            'format': 'full'\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, headers=headers, params=params, timeout=REQUEST_TIMEOUT)\n",
    "        \n",
    "        if response.status_code == 404:\n",
    "            logger.warning(f\"No Ensembl data found for {gene_symbol}\")\n",
    "            return {}\n",
    "        \n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        # Count exons from transcripts\n",
    "        total_exons = 0\n",
    "        canonical_exon_count = 0\n",
    "        \n",
    "        try:\n",
    "            if 'Transcript' in data:\n",
    "                transcript_data_raw = data.get('Transcript', {})\n",
    "                \n",
    "                # Handle both dict and list responses\n",
    "                transcript_items = []\n",
    "                if isinstance(transcript_data_raw, dict):\n",
    "                    transcript_items = transcript_data_raw.items()\n",
    "                elif isinstance(transcript_data_raw, list):\n",
    "                    for transcript in transcript_data_raw:\n",
    "                        if isinstance(transcript, dict):\n",
    "                            transcript_id = transcript.get('id', '')\n",
    "                            if transcript_id:\n",
    "                                transcript_items.append((transcript_id, transcript))\n",
    "                else:\n",
    "                    transcript_items = []\n",
    "                \n",
    "                for transcript_id, transcript in transcript_items:\n",
    "                    if not transcript_id or not transcript or not isinstance(transcript, dict):\n",
    "                        continue\n",
    "                    \n",
    "                    try:\n",
    "                        # Count exons for this transcript\n",
    "                        exon_data = transcript.get('Exon', [])\n",
    "                        if isinstance(exon_data, dict):\n",
    "                            exon_count = len(exon_data)\n",
    "                        elif isinstance(exon_data, list):\n",
    "                            exon_count = len(exon_data)\n",
    "                        else:\n",
    "                            exon_count = 0\n",
    "                        \n",
    "                        total_exons = max(total_exons, exon_count)\n",
    "                        \n",
    "                        # Get canonical transcript exon count\n",
    "                        if transcript.get('is_canonical', False):\n",
    "                            canonical_exon_count = exon_count\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        logger.warning(f\"Error processing transcript {transcript_id}: {e}\")\n",
    "                        continue\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error processing transcript data for {gene_symbol}: {e}\")\n",
    "        \n",
    "        # Use canonical exon count if available, otherwise use max\n",
    "        final_exon_count = canonical_exon_count if canonical_exon_count > 0 else total_exons\n",
    "        \n",
    "        ensembl_data = {\n",
    "            'ensembl_geneid': data.get('id', ''),\n",
    "            'chromosome': data.get('seq_region_name', ''),\n",
    "            'assembly': 'GRCh38',  # Ensembl uses GRCh38 as default\n",
    "            'gene_type': data.get('biotype', ''),  # Gene type/biotype\n",
    "            'number_of_exons': final_exon_count,\n",
    "            'gene_start_position': data.get('start', ''),\n",
    "            'gene_end_position': data.get('end', ''),\n",
    "        }\n",
    "        \n",
    "        return ensembl_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Error fetching Ensembl data for {gene_symbol}: {e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f410447d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_ncbi_data(gene_symbol: str) -> Dict[str, Any]:\n",
    "    \"\"\"Fetch NCBI gene data using E-utilities API.\"\"\"\n",
    "    try:\n",
    "        # Step 1: Search for gene ID\n",
    "        search_url = f\"{NCBI_EUTILS_BASE}esearch.fcgi\"\n",
    "        search_params = {\n",
    "            'db': 'gene',\n",
    "            'term': f\"{gene_symbol}[gene name] AND human[orgn]\",\n",
    "            'retmode': 'json',\n",
    "            'retmax': 1\n",
    "        }\n",
    "        \n",
    "        response = requests.get(search_url, params=search_params, timeout=REQUEST_TIMEOUT)\n",
    "        response.raise_for_status()\n",
    "        search_data = response.json()\n",
    "        \n",
    "        id_list = search_data.get('esearchresult', {}).get('idlist', [])\n",
    "        \n",
    "        if not id_list:\n",
    "            logger.warning(f\"No NCBI gene ID found for {gene_symbol}\")\n",
    "            return {}\n",
    "        \n",
    "        gene_id = id_list[0]\n",
    "        time.sleep(RATE_LIMIT_DELAY)  # Rate limiting\n",
    "        \n",
    "        # Step 2: Fetch gene details\n",
    "        fetch_url = f\"{NCBI_EUTILS_BASE}efetch.fcgi\"\n",
    "        fetch_params = {\n",
    "            'db': 'gene',\n",
    "            'id': gene_id,\n",
    "            'retmode': 'xml'\n",
    "        }\n",
    "        \n",
    "        response = requests.get(fetch_url, params=fetch_params, timeout=REQUEST_TIMEOUT)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Parse XML response (simplified - in production you'd want proper XML parsing)\n",
    "        xml_content = response.text\n",
    "        \n",
    "        # Extract chromosome information from XML\n",
    "        chromosome = ''\n",
    "        if '<Chromosome>' in xml_content:\n",
    "            start = xml_content.find('<Chromosome>') + len('<Chromosome>')\n",
    "            end = xml_content.find('</Chromosome>', start)\n",
    "            if start < end:\n",
    "                chromosome = xml_content[start:end].strip()\n",
    "        \n",
    "        ncbi_data = {\n",
    "            'ncbi_gene_id': gene_id,\n",
    "            'chromosome': chromosome\n",
    "        }\n",
    "        \n",
    "        time.sleep(RATE_LIMIT_DELAY)  # Rate limiting\n",
    "        return ncbi_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Error fetching NCBI data for {gene_symbol}: {e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5b46d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_genage_data(gene_symbol: str) -> Dict[str, Any]:\n",
    "    \"\"\"Fetch GenAge data for a gene symbol to get additional aliases.\"\"\"\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Longevity-Genes-Fetcher/1.0'\n",
    "        }\n",
    "        \n",
    "        # Try both URL formats based on the GenAge structure\n",
    "        # Based on testing, ?hgnc=SYMBOL works better than ?symbol=SYMBOL\n",
    "        urls_to_try = [\n",
    "            f\"{GENAGE_BASE_URL}/genes/entry.php?hgnc={gene_symbol}\",    # Try symbol as hgnc parameter\n",
    "            f\"{GENAGE_BASE_URL}/genes/entry.php?symbol={gene_symbol}\",   # Fallback to symbol parameter\n",
    "        ]\n",
    "        \n",
    "        for url in urls_to_try:\n",
    "            try:\n",
    "                response = requests.get(url, headers=headers, timeout=REQUEST_TIMEOUT)\n",
    "                \n",
    "                if response.status_code != 200:\n",
    "                    continue\n",
    "                \n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                page_text = soup.get_text()\n",
    "                \n",
    "                # Check if this is a valid gene page (not the \"No query selected\" page)\n",
    "                if \"No query selected\" in page_text or len(page_text) < 5000:\n",
    "                    continue\n",
    "                \n",
    "                # Look for gene aliases in the page content\n",
    "                aliases = []\n",
    "                \n",
    "                # Method 1: Look for the specific \"Aliases\" section in GenAge\n",
    "                # Based on the NFE2L2 example, look for \"Aliases\" as a header/field\n",
    "                h2_headings = soup.find_all(['h2', 'h3', 'h4'])\n",
    "                for heading in h2_headings:\n",
    "                    if heading.get_text().strip().lower() in ['aliases', 'alias']:\n",
    "                        # Look for the next content after this heading\n",
    "                        next_element = heading.find_next_sibling()\n",
    "                        while next_element:\n",
    "                            if next_element.name in ['p', 'div', 'td']:\n",
    "                                alias_text = next_element.get_text().strip()\n",
    "                                if alias_text and alias_text.lower() != gene_symbol.lower():\n",
    "                                    # Split by common separators and clean\n",
    "                                    alias_parts = re.split(r'[,;|/\\n]', alias_text)\n",
    "                                    for part in alias_parts:\n",
    "                                        clean_alias = part.strip()\n",
    "                                        if clean_alias and clean_alias.lower() != gene_symbol.lower() and len(clean_alias) > 1:\n",
    "                                            aliases.append(clean_alias)\n",
    "                            elif next_element.name in ['h2', 'h3', 'h4', 'table']:\n",
    "                                break\n",
    "                            next_element = next_element.find_next_sibling()\n",
    "                        break\n",
    "                \n",
    "                # Method 2: Look for aliases in table structures\n",
    "                # Find tables and look for \"Aliases\" or \"HGNC symbol\" rows\n",
    "                tables = soup.find_all('table')\n",
    "                for table in tables:\n",
    "                    rows = table.find_all('tr')\n",
    "                    for row in rows:\n",
    "                        cells = row.find_all(['td', 'th'])\n",
    "                        if len(cells) >= 2:\n",
    "                            key = cells[0].get_text().strip().lower()\n",
    "                            value = cells[1].get_text().strip()\n",
    "                            \n",
    "                            # Look for alias/synonym related fields\n",
    "                            if any(term in key for term in ['alias', 'aliases', 'synonym', 'alternative', 'other names']):\n",
    "                                if value and value.lower() != gene_symbol.lower():\n",
    "                                    # Split by common separators and clean\n",
    "                                    alias_parts = re.split(r'[,;|/\\n]', value)\n",
    "                                    for part in alias_parts:\n",
    "                                        clean_alias = part.strip()\n",
    "                                        if clean_alias and clean_alias.lower() != gene_symbol.lower() and len(clean_alias) > 1:\n",
    "                                            aliases.append(clean_alias)\n",
    "                \n",
    "                # Method 3: Look for aliases using text patterns specific to GenAge format\n",
    "                # Based on the NFE2L2 page structure\n",
    "                alias_patterns = [\n",
    "                    r'Aliases\\s*\\n\\s*([^\\n]+)',  # Look for \"Aliases\" followed by content\n",
    "                    r'Aliases[:\\s]*([^\\n\\r]+)',  # Look for \"Aliases:\" format\n",
    "                    r'HGNC symbol\\s*\\n\\s*([^\\n]+)\\s*\\n\\s*Aliases\\s*\\n\\s*([^\\n]+)',  # Multi-line pattern\n",
    "                ]\n",
    "                \n",
    "                for pattern in alias_patterns:\n",
    "                    matches = re.findall(pattern, page_text, re.IGNORECASE | re.MULTILINE)\n",
    "                    for match in matches:\n",
    "                        if isinstance(match, tuple):\n",
    "                            # Handle tuple matches (multiple groups)\n",
    "                            for group in match:\n",
    "                                if group.strip():\n",
    "                                    # Clean special characters (like \\xa0 non-breaking spaces)\n",
    "                                    clean_group = group.replace('\\xa0', ' ').strip()\n",
    "                                    alias_parts = re.split(r'[,;|/\\n]', clean_group)\n",
    "                                    for part in alias_parts:\n",
    "                                        clean_alias = part.strip()\n",
    "                                        if clean_alias and clean_alias.lower() != gene_symbol.lower() and len(clean_alias) > 1:\n",
    "                                            aliases.append(clean_alias)\n",
    "                        else:\n",
    "                            # Handle single string matches\n",
    "                            # Clean special characters (like \\xa0 non-breaking spaces)\n",
    "                            clean_match = match.replace('\\xa0', ' ').strip()\n",
    "                            alias_parts = re.split(r'[,;|/\\n]', clean_match)\n",
    "                            for part in alias_parts:\n",
    "                                clean_alias = part.strip()\n",
    "                                if clean_alias and clean_alias.lower() != gene_symbol.lower() and len(clean_alias) > 1:\n",
    "                                    aliases.append(clean_alias)\n",
    "                \n",
    "                # Method 4: Simple line-by-line parsing for GenAge format\n",
    "                lines = page_text.split('\\n')\n",
    "                for i, line in enumerate(lines):\n",
    "                    if 'aliases' in line.lower() and i < len(lines) - 1:\n",
    "                        next_line = lines[i+1].strip().replace('\\xa0', ' ').strip()\n",
    "                        if next_line and next_line.lower() != gene_symbol.lower():\n",
    "                            alias_parts = re.split(r'[,;|/\\n]', next_line)\n",
    "                            for part in alias_parts:\n",
    "                                clean_alias = part.strip()\n",
    "                                if clean_alias and clean_alias.lower() != gene_symbol.lower() and len(clean_alias) > 1:\n",
    "                                    aliases.append(clean_alias)\n",
    "                        break\n",
    "                \n",
    "                # Remove duplicates and empty entries, and filter out generic placeholder text\n",
    "                unique_aliases = []\n",
    "                seen = set()\n",
    "                # Generic terms to exclude from aliases\n",
    "                exclude_terms = {'common name', 'n/a', 'none', 'unknown', 'not available', 'na'}\n",
    "                \n",
    "                for alias in aliases:\n",
    "                    clean_alias = alias.strip()\n",
    "                    if (clean_alias and \n",
    "                        clean_alias.lower() not in seen and \n",
    "                        clean_alias.lower() not in exclude_terms):\n",
    "                        unique_aliases.append(clean_alias)\n",
    "                        seen.add(clean_alias.lower())\n",
    "                \n",
    "                genage_data = {}\n",
    "                if unique_aliases:\n",
    "                    genage_data['genage_aliases'] = ', '.join(unique_aliases)\n",
    "                \n",
    "                # Extract description from GenAge page\n",
    "                description_text = \"\"\n",
    "                \n",
    "                # Look for the description section after \"Description\" heading\n",
    "                lines = page_text.split('\\n')\n",
    "                for i, line in enumerate(lines):\n",
    "                    if 'description' in line.lower() and i < len(lines) - 1:\n",
    "                        # Found description heading, collect the next content\n",
    "                        description_lines = []\n",
    "                        j = i + 1\n",
    "                        # Collect lines until we hit another heading or empty line followed by heading\n",
    "                        while j < len(lines):\n",
    "                            current_line = lines[j].strip()\n",
    "                            if not current_line:\n",
    "                                j += 1\n",
    "                                continue\n",
    "                            # Stop if we hit another major heading (usually capitalized)\n",
    "                            if (len(current_line) < 100 and \n",
    "                                (current_line.isupper() or \n",
    "                                 any(word in current_line.lower() for word in ['cytogenetic', 'protein information', 'gene ontology', 'protein interactions', 'homologs']))):\n",
    "                                break\n",
    "                            # Add non-empty lines to description\n",
    "                            if current_line and len(current_line) > 10:  # Skip very short lines\n",
    "                                description_lines.append(current_line)\n",
    "                            j += 1\n",
    "                            # Limit description length to avoid very long text\n",
    "                            if len('\\n'.join(description_lines)) > 10000:\n",
    "                                break\n",
    "                        \n",
    "                        # Join the description lines and clean up\n",
    "                        if description_lines:\n",
    "                            description_text = '\\n'.join(description_lines).strip()\n",
    "                            # Clean up any excessive whitespace\n",
    "                            description_text = re.sub(r'\\s+', ' ', description_text)\n",
    "                            # Limit to reasonable length\n",
    "                            if len(description_text) > 10000:\n",
    "                                description_text = description_text[:10000] + \"...\"\n",
    "                        \n",
    "                        break\n",
    "                \n",
    "                if description_text:\n",
    "                    # Clean references from the description text\n",
    "                    cleaned_description = clean_references_from_text(description_text)\n",
    "                    genage_data['genage_description'] = cleaned_description\n",
    "                \n",
    "                # Also check if this gene is in GenAge database for longevity/aging relevance\n",
    "                if any(term in page_text.lower() for term in ['ageing', 'aging', 'longevity', 'senescence']):\n",
    "                    genage_data['genage_relevance'] = True\n",
    "                \n",
    "                # If we found data, return it\n",
    "                if genage_data:\n",
    "                    return genage_data\n",
    "                    \n",
    "            except Exception as e:\n",
    "                logger.debug(f\"Error accessing GenAge URL {url} for {gene_symbol}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return {}\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.debug(f\"Error fetching GenAge data for {gene_symbol}: {e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee091c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_gene_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Enrich the DataFrame with data from all three APIs.\"\"\"\n",
    "    logger.info(f\"Starting to enrich {len(df)} genes with API data\")\n",
    "    \n",
    "    enriched_records = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        gene_symbol = row['gene_symbol']\n",
    "        gene_name = row['gene_name']\n",
    "        \n",
    "        logger.info(f\"Processing {index+1}/{len(df)}: {gene_symbol}\")\n",
    "        \n",
    "        # Initialize the enriched record with original data and new columns\n",
    "        enriched_record = {\n",
    "            'gene_symbol': gene_symbol,\n",
    "            'gene_name': gene_name,\n",
    "            'gene_symbol_aliases': '',\n",
    "            'hgnc_gene_id': '',\n",
    "            'ncbi_gene_id': '',\n",
    "            'ensembl_geneid': '',\n",
    "            'chromosome': '',\n",
    "            'assembly': 'GRCh38',  # Default assembly\n",
    "            'gene_type': '',\n",
    "            'number_of_exons': '',\n",
    "            'gene_start_position': '',\n",
    "            'gene_end_position': '',\n",
    "            'description': '',\n",
    "            'created_at': datetime.now().isoformat(),\n",
    "            'updated_at': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        # Fetch data from HGNC\n",
    "        hgnc_data = fetch_hgnc_data(gene_symbol)\n",
    "        if hgnc_data:\n",
    "            enriched_record.update({\n",
    "                'gene_symbol_aliases': hgnc_data.get('gene_symbol_aliases', ''),\n",
    "                'hgnc_gene_id': hgnc_data.get('hgnc_gene_id', ''),\n",
    "            })\n",
    "            # Use HGNC chromosome if available\n",
    "            if hgnc_data.get('chromosome'):\n",
    "                enriched_record['chromosome'] = hgnc_data['chromosome']\n",
    "        \n",
    "        # Fetch data from Ensembl\n",
    "        ensembl_data = fetch_ensembl_data(gene_symbol)\n",
    "        ensembl_gene_id = ''\n",
    "        if ensembl_data:\n",
    "            enriched_record.update({\n",
    "                'ensembl_geneid': ensembl_data.get('ensembl_geneid', ''),\n",
    "                'assembly': ensembl_data.get('assembly', 'GRCh38'),\n",
    "                'gene_type': ensembl_data.get('gene_type', ''),\n",
    "                'number_of_exons': ensembl_data.get('number_of_exons', ''),\n",
    "                'gene_start_position': ensembl_data.get('gene_start_position', ''),\n",
    "                'gene_end_position': ensembl_data.get('gene_end_position', ''),\n",
    "            })\n",
    "            # Use Ensembl chromosome if HGNC didn't provide one\n",
    "            if not enriched_record['chromosome'] and ensembl_data.get('chromosome'):\n",
    "                enriched_record['chromosome'] = ensembl_data['chromosome']\n",
    "            \n",
    "            ensembl_gene_id = ensembl_data.get('ensembl_geneid', '')\n",
    "        \n",
    "        # Fetch data from NCBI\n",
    "        ncbi_data = fetch_ncbi_data(gene_symbol)\n",
    "        if ncbi_data:\n",
    "            enriched_record.update({\n",
    "                'ncbi_gene_id': ncbi_data.get('ncbi_gene_id', ''),\n",
    "            })\n",
    "            # Use NCBI chromosome if neither HGNC nor Ensembl provided one\n",
    "            if not enriched_record['chromosome'] and ncbi_data.get('chromosome'):\n",
    "                enriched_record['chromosome'] = ncbi_data['chromosome']\n",
    "        \n",
    "        # Fetch data from GenAge to get additional aliases and description\n",
    "        genage_data = fetch_genage_data(gene_symbol)\n",
    "        if genage_data:\n",
    "            # Handle GenAge aliases\n",
    "            if genage_data.get('genage_aliases'):\n",
    "                # Combine HGNC and GenAge aliases\n",
    "                hgnc_aliases = enriched_record.get('gene_symbol_aliases', '')\n",
    "                genage_aliases = genage_data.get('genage_aliases', '')\n",
    "                \n",
    "                # Combine aliases from both sources\n",
    "                all_aliases = []\n",
    "                if hgnc_aliases:\n",
    "                    all_aliases.extend([alias.strip() for alias in hgnc_aliases.split(',') if alias.strip()])\n",
    "                if genage_aliases:\n",
    "                    all_aliases.extend([alias.strip() for alias in genage_aliases.split(',') if alias.strip()])\n",
    "                \n",
    "                # Remove duplicates, the original gene symbol, and generic placeholder text\n",
    "                unique_aliases = []\n",
    "                seen = set()\n",
    "                # Generic terms to exclude from aliases\n",
    "                exclude_terms = {'common name', 'n/a', 'none', 'unknown', 'not available', 'na'}\n",
    "                \n",
    "                for alias in all_aliases:\n",
    "                    clean_alias = alias.strip()\n",
    "                    if (clean_alias and \n",
    "                        clean_alias.lower() != gene_symbol.lower() and \n",
    "                        clean_alias.lower() not in seen and \n",
    "                        clean_alias.lower() not in exclude_terms):\n",
    "                        unique_aliases.append(clean_alias)\n",
    "                        seen.add(clean_alias.lower())\n",
    "                \n",
    "                # Update the aliases field with combined data\n",
    "                if unique_aliases:\n",
    "                    enriched_record['gene_symbol_aliases'] = ', '.join(unique_aliases)\n",
    "            \n",
    "            # Handle GenAge description (already cleaned of references)\n",
    "            if genage_data.get('genage_description'):\n",
    "                enriched_record['description'] = genage_data.get('genage_description', '')\n",
    "        \n",
    "        enriched_records.append(enriched_record)\n",
    "        \n",
    "        # Add delay between requests to be respectful to APIs\n",
    "        time.sleep(0.1)\n",
    "        \n",
    "        # Progress update every 10 genes\n",
    "        if (index + 1) % 10 == 0:\n",
    "            logger.info(f\"Processed {index+1}/{len(df)} genes\")\n",
    "    \n",
    "    # Create new DataFrame\n",
    "    enriched_df = pd.DataFrame(enriched_records)\n",
    "    \n",
    "    # Reorder columns to match requested order\n",
    "    column_order = [\n",
    "        'gene_symbol',\n",
    "        'gene_symbol_aliases',\n",
    "        'gene_name',\n",
    "        'hgnc_gene_id',\n",
    "        'ncbi_gene_id',\n",
    "        'ensembl_geneid',\n",
    "        'chromosome',\n",
    "        'assembly',\n",
    "        'gene_type',\n",
    "        'number_of_exons',\n",
    "        'gene_start_position',\n",
    "        'gene_end_position',\n",
    "        'description',\n",
    "        'created_at',\n",
    "        'updated_at'\n",
    "    ]\n",
    "    \n",
    "    # Ensure all columns exist and reorder\n",
    "    enriched_df = enriched_df.reindex(columns=column_order)\n",
    "    logger.info(f\"Enriched {len(enriched_df)} genes with API data\")\n",
    "    \n",
    "    return enriched_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de15d0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_enriched_data(df: pd.DataFrame) -> None:\n",
    "    \"\"\"Save the enriched DataFrame to CSV.\"\"\"\n",
    "    try:\n",
    "        df.to_csv(OUTPUT_CSV, index=False)\n",
    "        logger.info(f\"Saved enriched data to {OUTPUT_CSV}\")\n",
    "        \n",
    "        # Print summary statistics\n",
    "        logger.info(\"Enrichment Summary:\")\n",
    "        logger.info(f\"  Total genes: {len(df)}\")\n",
    "        logger.info(f\"  Genes with HGNC data: {len(df[df['hgnc_gene_id'] != ''])}\")\n",
    "        logger.info(f\"  Genes with Ensembl data: {len(df[df['ensembl_geneid'] != ''])}\")\n",
    "        logger.info(f\"  Genes with NCBI data: {len(df[df['ncbi_gene_id'] != ''])}\")\n",
    "        logger.info(f\"  Genes with chromosome info: {len(df[df['chromosome'] != ''])}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error saving enriched data: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d51065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(test_mode: bool = False):\n",
    "    \"\"\"Main execution function.\"\"\"\n",
    "    try:\n",
    "        if test_mode:\n",
    "            logger.info(\"Starting longevity genes details enrichment (TEST MODE - first 5 genes only)\")\n",
    "            output_file = \"master_longivity_genes_enriched_test.csv\"\n",
    "        else:\n",
    "            logger.info(\"Starting longevity genes details enrichment\")\n",
    "            output_file = OUTPUT_CSV\n",
    "        \n",
    "        # Read input CSV\n",
    "        df = read_input_csv()\n",
    "        \n",
    "        if df.empty:\n",
    "            logger.warning(\"Input CSV is empty. Exiting.\")\n",
    "            return\n",
    "        \n",
    "        # Limit to first 5 genes in test mode\n",
    "        if test_mode:\n",
    "            df = df.head(5)\n",
    "            logger.info(f\"TEST MODE: Processing only first 5 genes\")\n",
    "        \n",
    "        # Enrich the data\n",
    "        enriched_df = enrich_gene_data(df)\n",
    "        \n",
    "        # Save the enriched data\n",
    "        enriched_df.to_csv(output_file, index=False)\n",
    "        logger.info(f\"Saved enriched data to {output_file}\")\n",
    "        \n",
    "        # Print summary statistics\n",
    "        logger.info(\"Enrichment Summary:\")\n",
    "        logger.info(f\"  Total genes: {len(enriched_df)}\")\n",
    "        logger.info(f\"  Genes with HGNC data: {len(enriched_df[enriched_df['hgnc_gene_id'] != ''])}\")\n",
    "        logger.info(f\"  Genes with Ensembl data: {len(enriched_df[enriched_df['ensembl_geneid'] != ''])}\")\n",
    "        logger.info(f\"  Genes with NCBI data: {len(enriched_df[enriched_df['ncbi_gene_id'] != ''])}\")\n",
    "        logger.info(f\"  Genes with chromosome info: {len(enriched_df[enriched_df['chromosome'] != ''])}\")\n",
    "        logger.info(f\"  Genes with gene type: {len(enriched_df[enriched_df['gene_type'] != ''])}\")\n",
    "        logger.info(f\"  Genes with exon count: {len(enriched_df[enriched_df['number_of_exons'] != ''])}\")\n",
    "        logger.info(f\"  Genes with position info: {len(enriched_df[(enriched_df['gene_start_position'] != '') & (enriched_df['gene_end_position'] != '')])}\")\n",
    "        logger.info(f\"  Genes with description: {len(enriched_df[enriched_df['description'] != ''])}\")\n",
    "        \n",
    "        logger.info(\"Longevity genes details enrichment completed successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Enrichment failed: {e}\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a9d09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    test_mode = len(sys.argv) > 1 and sys.argv[1] == \"--test\"\n",
    "    main(test_mode=test_mode)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
